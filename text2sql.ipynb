{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Natural Language to SQL Query Generation\n\nIn this notebook, we perform fine tuning of pre-trained 7B variant code based LLM models, like CodeLLAMA, Codestral etc. The models are quantized to 4-bit models due to resource constraints. We use the Parameter Efficient Fine tuning techinue - Low Rank Adaptation method to fine-tune the models to generate SQL queries from text.  ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-25T02:42:44.958680Z","iopub.execute_input":"2024-08-25T02:42:44.959012Z","iopub.status.idle":"2024-08-25T02:42:45.354523Z","shell.execute_reply.started":"2024-08-25T02:42:44.958978Z","shell.execute_reply":"2024-08-25T02:42:45.353554Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Install Pytorch & other libraries\n!pip install \"torch==2.1.2\" tensorboard\n\n# Install Hugging Face libraries\n!pip install  --upgrade \\\n  \"transformers==4.36.2\" \\\n  \"datasets==2.16.1\" \\\n  \"accelerate==0.26.1\" \\\n  \"evaluate==0.4.1\" \\\n  \"bitsandbytes==0.42.0\" \\\n  # \"trl==0.7.10\" # \\\n  # \"peft==0.7.1\" \\\n\n# install peft & trl from github\n!pip install git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e --upgrade\n!pip install git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-08-25T20:41:22.494985Z","iopub.execute_input":"2024-08-25T20:41:22.495573Z","iopub.status.idle":"2024-08-25T20:45:08.486788Z","shell.execute_reply.started":"2024-08-25T20:41:22.495533Z","shell.execute_reply":"2024-08-25T20:45:08.485533Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torch==2.1.2\n  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.16.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.1.0 (from torch==2.1.2)\n  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2)\n  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.62.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.6)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (70.0.0)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\nDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 triton-2.1.0\nCollecting transformers==4.36.2\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting datasets==2.16.1\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nCollecting accelerate==0.26.1\n  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\nCollecting evaluate==0.4.1\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting bitsandbytes==0.42.0\n  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2.32.3)\nCollecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.4.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (4.66.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (0.6)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.1) (3.9.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1) (2.1.2)\nCollecting responses<0.19 (from evaluate==0.4.1)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0) (1.14.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.36.2) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.26.1) (12.6.20)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.16.1)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.26.1) (1.3.0)\nDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, dill, responses, multiprocess, bitsandbytes, tokenizers, transformers, datasets, accelerate, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.6.1\n    Uninstalling fsspec-2024.6.1:\n      Successfully uninstalled fsspec-2024.6.1\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.21.0\n    Uninstalling datasets-2.21.0:\n      Successfully uninstalled datasets-2.21.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.33.0\n    Uninstalling accelerate-0.33.0:\n      Successfully uninstalled accelerate-0.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.2 requires cubinlinker, which is not installed.\ncudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.2 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\ncudf 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\ngcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\ns3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.26.1 bitsandbytes-0.42.0 datasets-2.16.1 dill-0.3.7 evaluate-0.4.1 fsspec-2023.10.0 multiprocess-0.70.15 responses-0.18.0 tokenizers-0.15.2 transformers-4.36.2\nCollecting git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n  Cloning https://github.com/huggingface/trl (to revision a3c5b7178ac4f65569975efadc97db2f3749c65e) to /tmp/pip-req-build-e7pntk8k\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl /tmp/pip-req-build-e7pntk8k\n  Running command git rev-parse -q --verify 'sha^a3c5b7178ac4f65569975efadc97db2f3749c65e'\n  Running command git fetch -q https://github.com/huggingface/trl a3c5b7178ac4f65569975efadc97db2f3749c65e\n  Running command git checkout -q a3c5b7178ac4f65569975efadc97db2f3749c65e\n  Resolved https://github.com/huggingface/trl to commit a3c5b7178ac4f65569975efadc97db2f3749c65e\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11.dev0) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11.dev0) (4.36.2)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11.dev0) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11.dev0) (0.26.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11.dev0) (2.16.1)\nCollecting tyro>=0.5.11 (from trl==0.7.11.dev0)\n  Downloading tyro-0.8.8-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (2023.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.11.dev0) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl==0.7.11.dev0) (12.6.20)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (0.24.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (0.4.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.11.dev0) (4.66.4)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11.dev0) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11.dev0) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.11.dev0)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.7.11.dev0) (5.9.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.11.dev0) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.11.dev0) (0.6)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.11.dev0) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.11.dev0) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.11.dev0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.11.dev0) (0.70.15)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.11.dev0) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.11.dev0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.11.dev0) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.11.dev0) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.11.dev0) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.11.dev0) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.11.dev0) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.7.11.dev0) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.11.dev0) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.7.11.dev0) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.11.dev0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.11.dev0) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.11.dev0) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.7.11.dev0) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.11.dev0) (1.16.0)\nDownloading tyro-0.8.8-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: trl\n  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for trl: filename=trl-0.7.11.dev0-py3-none-any.whl size=151090 sha256=bd6711e4379490ff27e749b1c7b83badee39779b498b9c6f230a803e23dc5617\n  Stored in directory: /root/.cache/pip/wheels/69/fc/ec/e718a169cea1752bd9c3eb798e9d8a56686d0752c49f97e1c1\nSuccessfully built trl\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.7.1 trl-0.7.11.dev0 tyro-0.8.8\nCollecting git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f\n  Cloning https://github.com/huggingface/peft (to revision 4a1559582281fc3c9283892caea8ccef1d6f5a4f) to /tmp/pip-req-build-1lhjnwmr\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-1lhjnwmr\n  Running command git rev-parse -q --verify 'sha^4a1559582281fc3c9283892caea8ccef1d6f5a4f'\n  Running command git fetch -q https://github.com/huggingface/peft 4a1559582281fc3c9283892caea8ccef1d6f5a4f\n  Running command git checkout -q 4a1559582281fc3c9283892caea8ccef1d6f5a4f\n  Resolved https://github.com/huggingface/peft to commit 4a1559582281fc3c9283892caea8ccef1d6f5a4f\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (4.36.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (0.26.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.2.dev0) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2023.10.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.7.2.dev0) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.2.dev0) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.7.2.dev0) (12.6.20)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.7.2.dev0) (2024.5.15)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.7.2.dev0) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.7.2.dev0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.7.2.dev0) (1.3.0)\nBuilding wheels for collected packages: peft\n  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peft: filename=peft-0.7.2.dev0-py3-none-any.whl size=183144 sha256=07d36453ea21eb0831bf1ff84bf0825a6a4070dbf080424fa0c4d8deead6037c\n  Stored in directory: /root/.cache/pip/wheels/94/88/30/67a50390d00daa42c311fb8b162fb3b320e9cdab6bd0bb8568\nSuccessfully built peft\nInstalling collected packages: peft\nSuccessfully installed peft-0.7.2.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n\n# Set the Hugging Face access token as an environment variable\nos.environ['HUGGINGFACE_TOKEN'] = 'abcd'\n\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-08-25T20:45:08.488738Z","iopub.execute_input":"2024-08-25T20:45:08.489067Z","iopub.status.idle":"2024-08-25T20:45:08.494194Z","shell.execute_reply.started":"2024-08-25T20:45:08.489033Z","shell.execute_reply":"2024-08-25T20:45:08.493333Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Model Quantization\n\nConverting fp32-bit models to fp4-bit models","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom trl import setup_chat_format\n\nmodel_id = \"codellama/CodeLlama-7b-Instruct-hf\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=os.getenv('HUGGINGFACE_TOKEN'))\nmodel = AutoModelForCausalLM.from_pretrained(\n                                              model_id,\n                                              quantization_config=bnb_config,\n                                              device_map={\"\":0},\n                                              _attn_implementation=\"eager\",\n                                              use_auth_token=os.getenv('HUGGINGFACE_TOKEN'))\n\nprint(\"Tokenizer : \", tokenizer)\n\n # set chat template to OAI chatML\nmodel, tokenizer = setup_chat_format(model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:46:37.998006Z","iopub.execute_input":"2024-08-25T02:46:37.998302Z","iopub.status.idle":"2024-08-25T02:48:23.373097Z","shell.execute_reply.started":"2024-08-25T02:46:37.998269Z","shell.execute_reply":"2024-08-25T02:48:23.372084Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:690: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e6f25355434f56a92ba43b07b9e896"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a16804c226134bf38569c0a333e482bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf9a80e57b647fc91931f444548dcef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65763b21555d43ebbb5ebdf0cc8f053c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/646 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002f5be8b9644a5fb294f0da097a246b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df9a1e6a52e745a69e00cd0740d5911d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50fca4720d3846548f310c89ac0e29eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d668ee82e9041369d299d183d7efcbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e486a536864a5ab60385f5f70695ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9a81a3bccf9403e9c1a78d2cc764328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a6745a117f5454dba2d08ae7b8f5c75"}},"metadata":{}},{"name":"stdout","text":"Tokenizer :  CodeLlamaTokenizerFast(name_or_path='codellama/CodeLlama-7b-Instruct-hf', vocab_size=32016, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'additional_special_tokens': ['▁<PRE>', '▁<MID>', '▁<SUF>', '▁<EOT>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32007: AddedToken(\"▁<PRE>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32008: AddedToken(\"▁<SUF>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32009: AddedToken(\"▁<MID>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32010: AddedToken(\"▁<EOT>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting up model for k-bit training\nfrom peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:23.375637Z","iopub.execute_input":"2024-08-25T02:48:23.375968Z","iopub.status.idle":"2024-08-25T02:48:23.425083Z","shell.execute_reply.started":"2024-08-25T02:48:23.375934Z","shell.execute_reply":"2024-08-25T02:48:23.424035Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Function to get the number of trainable parameters\n\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:23.426429Z","iopub.execute_input":"2024-08-25T02:48:23.426858Z","iopub.status.idle":"2024-08-25T02:48:23.434217Z","shell.execute_reply.started":"2024-08-25T02:48:23.426809Z","shell.execute_reply":"2024-08-25T02:48:23.433350Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## PEFT-LORA fine tune setup\n\nfrom peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=\"all-linear\",\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:23.435268Z","iopub.execute_input":"2024-08-25T02:48:23.435555Z","iopub.status.idle":"2024-08-25T02:48:23.962381Z","shell.execute_reply.started":"2024-08-25T02:48:23.435524Z","shell.execute_reply":"2024-08-25T02:48:23.961401Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"trainable params: 19988480 || all params: 3520548864 || trainable%: 0.5677660152482406\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Dataset Setup\n\n","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Convert dataset to OAI messages\nsystem_message = \"\"\"You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\nSCHEMA:\n{schema}\"\"\"\n\ndef create_conversation(sample):\n    return {\n    \"messages\": [\n      {\"role\": \"system\", \"content\": system_message.format(schema=sample[\"context\"])},\n      {\"role\": \"user\", \"content\": sample[\"question\"]},\n      {\"role\": \"assistant\", \"content\": sample[\"answer\"]}\n    ]\n  }\n\n# Load dataset from the hub\ndataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\ndataset = dataset.shuffle().select(range(12500))\n\n# Convert dataset to OAI messages\ndataset = dataset.map(create_conversation, remove_columns=dataset.features,batched=False)\n# split dataset into 10,000 training samples and 2,500 test samples\ndataset = dataset.train_test_split(test_size=2500/12500)\n\nprint(dataset[\"train\"][345][\"messages\"])\n\n# save datasets to disk\ndataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\ndataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:23.963885Z","iopub.execute_input":"2024-08-25T02:48:23.964294Z","iopub.status.idle":"2024-08-25T02:48:29.226225Z","shell.execute_reply.started":"2024-08-25T02:48:23.964248Z","shell.execute_reply":"2024-08-25T02:48:29.225269Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/4.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1a1451e4c204a319742e0a37e57c654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/21.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66fe3ad7dc4f4718bb274315a8ed14bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfd1c1d61a9e4690a05e6806654a0244"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb57fc7c2594f56a1bbfcfca19ac4cc"}},"metadata":{}},{"name":"stdout","text":"[{'content': 'You are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\\nSCHEMA:\\nCREATE TABLE table_name_82 (area__sq_mi_ INTEGER, rank VARCHAR)', 'role': 'system'}, {'content': 'What is the smallest area (sq mi) that has 160 as it rank?', 'role': 'user'}, {'content': 'SELECT MIN(area__sq_mi_) FROM table_name_82 WHERE rank = 160', 'role': 'assistant'}]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Creating json from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4152c2727bab46c58da4d2d65ecbebfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"129475b8ad6f443892345b04f2d98eb2"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"1187678"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load jsonl data from disk\ndataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:29.227595Z","iopub.execute_input":"2024-08-25T02:48:29.228011Z","iopub.status.idle":"2024-08-25T02:48:29.528842Z","shell.execute_reply.started":"2024-08-25T02:48:29.227967Z","shell.execute_reply":"2024-08-25T02:48:29.528085Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7cee27129644638af8b4da29f231a8b"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    output_dir=\"codellama-7b-text-to-sql\", # directory to save and repository id\n    num_train_epochs=3,                     # number of training epochs\n    per_device_train_batch_size=1,          # batch size per device during training\n    gradient_accumulation_steps=1,          # number of steps before performing a backward/update pass\n    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n    logging_steps=5,                       # log every 10 steps\n    save_strategy=\"epoch\",                  # save checkpoint every epoch\n    learning_rate=2e-4,                     # learning rate, based on QLoRA paper\n    bf16=False,                              # use bfloat16 precision\n    tf32=False,                              # use tf32 precision\n    fp16=True,\n    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n    warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper\n    lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n    push_to_hub=False,                       # push model to hub\n    report_to=\"tensorboard\",                # report metrics to tensorboard\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:29.529998Z","iopub.execute_input":"2024-08-25T02:48:29.530290Z","iopub.status.idle":"2024-08-25T02:48:29.538463Z","shell.execute_reply.started":"2024-08-25T02:48:29.530259Z","shell.execute_reply":"2024-08-25T02:48:29.537671Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\nmax_seq_length = 3072 # max sequence length for model and packing of the dataset\n\ntrainer = SFTTrainer(\n    model=model,\n    args=args,\n    train_dataset=dataset,\n    peft_config=config,\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    packing=True,\n    dataset_kwargs={\n        \"add_special_tokens\": False,  # We template with special tokens\n        \"append_concat_token\": False, # No need to add additional separator token\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:29.539673Z","iopub.execute_input":"2024-08-25T02:48:29.539997Z","iopub.status.idle":"2024-08-25T02:48:32.749041Z","shell.execute_reply.started":"2024-08-25T02:48:29.539964Z","shell.execute_reply":"2024-08-25T02:48:32.748013Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bd89537a9144600bae14103533338af"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:290: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\n\ntorch.cuda.empty_cache()\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:32.750275Z","iopub.execute_input":"2024-08-25T02:48:32.750947Z","iopub.status.idle":"2024-08-25T02:48:32.766524Z","shell.execute_reply.started":"2024-08-25T02:48:32.750909Z","shell.execute_reply":"2024-08-25T02:48:32.765376Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# start training, the model will be automatically saved to the hub and the output directory\ntrainer.train()\n\n# save model\n# trainer.save_model()\ntrainer.save_state()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T02:48:33.140654Z","iopub.execute_input":"2024-08-25T02:48:33.141076Z","iopub.status.idle":"2024-08-25T10:50:29.367556Z","shell.execute_reply.started":"2024-08-25T02:48:33.141028Z","shell.execute_reply":"2024-08-25T10:50:29.366691Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"You're using a CodeLlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1200/1200 8:01:30, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>3.364100</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.762500</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.870200</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.718600</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.698900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.620900</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.595400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.586400</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.563200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.566000</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.566700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.562300</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.555100</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.540000</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.527400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.550000</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.532300</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.533200</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.516600</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.516600</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.498800</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.522000</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.534900</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.497200</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.550700</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.512400</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.523400</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.507500</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.493500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.522700</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.499500</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.495300</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.508000</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.528600</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.495800</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.521500</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.482700</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.497300</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.492400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.492600</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.496400</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.483000</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.495900</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.496500</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.486300</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.485900</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.470500</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.492000</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.497200</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.522800</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>0.501200</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.493700</td>\n    </tr>\n    <tr>\n      <td>265</td>\n      <td>0.517400</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.483500</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.479400</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.496200</td>\n    </tr>\n    <tr>\n      <td>285</td>\n      <td>0.485000</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.484100</td>\n    </tr>\n    <tr>\n      <td>295</td>\n      <td>0.486900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.477000</td>\n    </tr>\n    <tr>\n      <td>305</td>\n      <td>0.474300</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.501400</td>\n    </tr>\n    <tr>\n      <td>315</td>\n      <td>0.455800</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.470100</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.486200</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.482600</td>\n    </tr>\n    <tr>\n      <td>335</td>\n      <td>0.500700</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.504300</td>\n    </tr>\n    <tr>\n      <td>345</td>\n      <td>0.467400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.486400</td>\n    </tr>\n    <tr>\n      <td>355</td>\n      <td>0.487700</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.507200</td>\n    </tr>\n    <tr>\n      <td>365</td>\n      <td>0.463900</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.457700</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.491800</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.491900</td>\n    </tr>\n    <tr>\n      <td>385</td>\n      <td>0.462400</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.466400</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>0.477000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.481200</td>\n    </tr>\n    <tr>\n      <td>405</td>\n      <td>0.441800</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.436100</td>\n    </tr>\n    <tr>\n      <td>415</td>\n      <td>0.411100</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.408600</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.436800</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.424500</td>\n    </tr>\n    <tr>\n      <td>435</td>\n      <td>0.419800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.413500</td>\n    </tr>\n    <tr>\n      <td>445</td>\n      <td>0.414800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.428100</td>\n    </tr>\n    <tr>\n      <td>455</td>\n      <td>0.422800</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.408000</td>\n    </tr>\n    <tr>\n      <td>465</td>\n      <td>0.438600</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.413400</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.434000</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.404400</td>\n    </tr>\n    <tr>\n      <td>485</td>\n      <td>0.414000</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.425200</td>\n    </tr>\n    <tr>\n      <td>495</td>\n      <td>0.415300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.431000</td>\n    </tr>\n    <tr>\n      <td>505</td>\n      <td>0.421500</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.432100</td>\n    </tr>\n    <tr>\n      <td>515</td>\n      <td>0.430400</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.422200</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>0.438700</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.439900</td>\n    </tr>\n    <tr>\n      <td>535</td>\n      <td>0.405600</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.421000</td>\n    </tr>\n    <tr>\n      <td>545</td>\n      <td>0.413300</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.432500</td>\n    </tr>\n    <tr>\n      <td>555</td>\n      <td>0.434900</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.447300</td>\n    </tr>\n    <tr>\n      <td>565</td>\n      <td>0.431700</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.417900</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>0.440400</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.418000</td>\n    </tr>\n    <tr>\n      <td>585</td>\n      <td>0.437600</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.437900</td>\n    </tr>\n    <tr>\n      <td>595</td>\n      <td>0.441900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.421300</td>\n    </tr>\n    <tr>\n      <td>605</td>\n      <td>0.404500</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.435700</td>\n    </tr>\n    <tr>\n      <td>615</td>\n      <td>0.447800</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.407700</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>0.434900</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.411900</td>\n    </tr>\n    <tr>\n      <td>635</td>\n      <td>0.422000</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.430000</td>\n    </tr>\n    <tr>\n      <td>645</td>\n      <td>0.423400</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.456300</td>\n    </tr>\n    <tr>\n      <td>655</td>\n      <td>0.417200</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.430800</td>\n    </tr>\n    <tr>\n      <td>665</td>\n      <td>0.411200</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.419200</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.437600</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.440700</td>\n    </tr>\n    <tr>\n      <td>685</td>\n      <td>0.405000</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.421800</td>\n    </tr>\n    <tr>\n      <td>695</td>\n      <td>0.422700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.447200</td>\n    </tr>\n    <tr>\n      <td>705</td>\n      <td>0.437200</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.431300</td>\n    </tr>\n    <tr>\n      <td>715</td>\n      <td>0.466800</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.416800</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>0.417600</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.417700</td>\n    </tr>\n    <tr>\n      <td>735</td>\n      <td>0.419500</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.448100</td>\n    </tr>\n    <tr>\n      <td>745</td>\n      <td>0.405100</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.433300</td>\n    </tr>\n    <tr>\n      <td>755</td>\n      <td>0.419100</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.419200</td>\n    </tr>\n    <tr>\n      <td>765</td>\n      <td>0.433100</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.409200</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>0.429400</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.434700</td>\n    </tr>\n    <tr>\n      <td>785</td>\n      <td>0.417700</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.426200</td>\n    </tr>\n    <tr>\n      <td>795</td>\n      <td>0.433400</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.402300</td>\n    </tr>\n    <tr>\n      <td>805</td>\n      <td>0.359100</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.359700</td>\n    </tr>\n    <tr>\n      <td>815</td>\n      <td>0.352200</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.370900</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>0.342500</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.362900</td>\n    </tr>\n    <tr>\n      <td>835</td>\n      <td>0.355300</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.350300</td>\n    </tr>\n    <tr>\n      <td>845</td>\n      <td>0.366500</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.356900</td>\n    </tr>\n    <tr>\n      <td>855</td>\n      <td>0.348100</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.349100</td>\n    </tr>\n    <tr>\n      <td>865</td>\n      <td>0.375200</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.350900</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>0.361600</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.355800</td>\n    </tr>\n    <tr>\n      <td>885</td>\n      <td>0.349800</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.348200</td>\n    </tr>\n    <tr>\n      <td>895</td>\n      <td>0.354400</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.365300</td>\n    </tr>\n    <tr>\n      <td>905</td>\n      <td>0.358700</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.354700</td>\n    </tr>\n    <tr>\n      <td>915</td>\n      <td>0.356600</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.355800</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>0.362000</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.374400</td>\n    </tr>\n    <tr>\n      <td>935</td>\n      <td>0.361100</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.370300</td>\n    </tr>\n    <tr>\n      <td>945</td>\n      <td>0.348300</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.380700</td>\n    </tr>\n    <tr>\n      <td>955</td>\n      <td>0.354100</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.373500</td>\n    </tr>\n    <tr>\n      <td>965</td>\n      <td>0.350100</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.349800</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>0.351500</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.355200</td>\n    </tr>\n    <tr>\n      <td>985</td>\n      <td>0.347000</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.360200</td>\n    </tr>\n    <tr>\n      <td>995</td>\n      <td>0.370300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.375600</td>\n    </tr>\n    <tr>\n      <td>1005</td>\n      <td>0.352700</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.371700</td>\n    </tr>\n    <tr>\n      <td>1015</td>\n      <td>0.347200</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.354300</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>0.377100</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.372900</td>\n    </tr>\n    <tr>\n      <td>1035</td>\n      <td>0.356000</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.340800</td>\n    </tr>\n    <tr>\n      <td>1045</td>\n      <td>0.350400</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.348800</td>\n    </tr>\n    <tr>\n      <td>1055</td>\n      <td>0.360200</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.378500</td>\n    </tr>\n    <tr>\n      <td>1065</td>\n      <td>0.367800</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.365900</td>\n    </tr>\n    <tr>\n      <td>1075</td>\n      <td>0.358800</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.369200</td>\n    </tr>\n    <tr>\n      <td>1085</td>\n      <td>0.353100</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.380800</td>\n    </tr>\n    <tr>\n      <td>1095</td>\n      <td>0.362000</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.372600</td>\n    </tr>\n    <tr>\n      <td>1105</td>\n      <td>0.354400</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.363600</td>\n    </tr>\n    <tr>\n      <td>1115</td>\n      <td>0.359300</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.358200</td>\n    </tr>\n    <tr>\n      <td>1125</td>\n      <td>0.367500</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.362400</td>\n    </tr>\n    <tr>\n      <td>1135</td>\n      <td>0.345300</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.371400</td>\n    </tr>\n    <tr>\n      <td>1145</td>\n      <td>0.356800</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.366400</td>\n    </tr>\n    <tr>\n      <td>1155</td>\n      <td>0.361700</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.371800</td>\n    </tr>\n    <tr>\n      <td>1165</td>\n      <td>0.333600</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.371400</td>\n    </tr>\n    <tr>\n      <td>1175</td>\n      <td>0.360700</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.378100</td>\n    </tr>\n    <tr>\n      <td>1185</td>\n      <td>0.372300</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.377700</td>\n    </tr>\n    <tr>\n      <td>1195</td>\n      <td>0.362500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.362800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:141: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:141: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:141: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Inference","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport transformers\nimport torch\n\nmodel = \"/kaggle/working/codellama-7b-text-to-sql/checkpoint-1200\"\n\ntokenizer = AutoTokenizer.from_pretrained(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T20:48:57.059742Z","iopub.execute_input":"2024-08-25T20:48:57.060561Z","iopub.status.idle":"2024-08-25T20:49:01.117307Z","shell.execute_reply.started":"2024-08-25T20:48:57.060521Z","shell.execute_reply":"2024-08-25T20:49:01.116370Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-08-25T20:49:12.526398Z","iopub.execute_input":"2024-08-25T20:49:12.527174Z","iopub.status.idle":"2024-08-25T20:49:12.534680Z","shell.execute_reply.started":"2024-08-25T20:49:12.527135Z","shell.execute_reply":"2024-08-25T20:49:12.533688Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"CodeLlamaTokenizerFast(name_or_path='/kaggle/working/codellama-7b-text-to-sql/checkpoint-1200', vocab_size=32016, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|im_start|>', 'eos_token': '<|im_end|>', 'unk_token': '<unk>', 'pad_token': '<|im_end|>', 'additional_special_tokens': ['<|im_end|>', '<|im_start|>', '▁<PRE>', '▁<MID>', '▁<SUF>', '▁<EOT>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32007: AddedToken(\"▁<PRE>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32008: AddedToken(\"▁<SUF>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32009: AddedToken(\"▁<MID>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32010: AddedToken(\"▁<EOT>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32016: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t32017: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}]},{"cell_type":"code","source":"pipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T20:51:02.353635Z","iopub.execute_input":"2024-08-25T20:51:02.354541Z","iopub.status.idle":"2024-08-25T20:54:53.166646Z","shell.execute_reply.started":"2024-08-25T20:51:02.354497Z","shell.execute_reply":"2024-08-25T20:54:53.165608Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/646 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffd877e3c9804556b96d2209fd838b66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f3dd71f1d8f489ca077905fb110195e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d69ff7fa804be4989c96399dff0637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8574a9e236c74995a5656698a97ed1a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6553f13f38cc4013a34df878fa56d5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0c02b74da1b40b2b882bae0a0b5835f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"734d79c783fd4bcc96fd620d8375e5e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec9fe7100a24249b86c0508da0b7773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bca75327d7ac44f8a01c0122b8f0b80d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b2f43fae93459fb1d02e0a11ebdf75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97166f6f5d2472abb99adf62f913220"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom random import randint\n \n# Load our test dataset\neval_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T21:43:13.176885Z","iopub.execute_input":"2024-08-25T21:43:13.177681Z","iopub.status.idle":"2024-08-25T21:43:13.298594Z","shell.execute_reply.started":"2024-08-25T21:43:13.177640Z","shell.execute_reply":"2024-08-25T21:43:13.297799Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generate_SQL():\n    # generate random index\n    rand_idx = randint(0, len(eval_dataset))\n    \n    # Test on sample\n    prompt = pipeline.tokenizer.apply_chat_template(eval_dataset[rand_idx][\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n    print(prompt)\n    outputs = pipeline(prompt, max_new_tokens=256, do_sample=False, temperature=0.1, top_k=50, top_p=0.1, eos_token_id=pipeline.tokenizer.eos_token_id, pad_token_id=pipeline.tokenizer.pad_token_id)\n \n    print(f\"Query:\\n{eval_dataset[rand_idx]['messages'][1]['content']}\")\n    print(f\"Original Answer:\\n{eval_dataset[rand_idx]['messages'][2]['content']}\")\n    print(f\"Generated Answer:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T21:52:35.798408Z","iopub.execute_input":"2024-08-25T21:52:35.799231Z","iopub.status.idle":"2024-08-25T21:52:35.805814Z","shell.execute_reply.started":"2024-08-25T21:52:35.799192Z","shell.execute_reply":"2024-08-25T21:52:35.804857Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"generate_SQL()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T21:52:40.164361Z","iopub.execute_input":"2024-08-25T21:52:40.165250Z","iopub.status.idle":"2024-08-25T21:52:43.951195Z","shell.execute_reply.started":"2024-08-25T21:52:40.165209Z","shell.execute_reply":"2024-08-25T21:52:43.950259Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST] <<SYS>>\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\nSCHEMA:\nCREATE TABLE table_27892955_1 (title VARCHAR, directed_by VARCHAR, no_in_series VARCHAR)\n<</SYS>>\n\nWhat is the name of episode 120 in the series that Mike Rohl directed? [/INST]\nQuery:\nWhat is the name of episode 120 in the series that Mike Rohl directed?\nOriginal Answer:\nSELECT title FROM table_27892955_1 WHERE directed_by = \"Mike Rohl\" AND no_in_series = 120\nGenerated Answer:\nSELECT title FROM table_27892955_1 WHERE directed_by = 'Mike Rohl' AND no_in_series = 120;\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_SQL()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T21:52:52.259712Z","iopub.execute_input":"2024-08-25T21:52:52.260109Z","iopub.status.idle":"2024-08-25T21:52:56.599715Z","shell.execute_reply.started":"2024-08-25T21:52:52.260073Z","shell.execute_reply":"2024-08-25T21:52:56.598771Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST] <<SYS>>\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\nSCHEMA:\nCREATE TABLE table_name_23 (term_end VARCHAR, political_party VARCHAR, born_died VARCHAR)\n<</SYS>>\n\nWhich Term end has a Political Party of balli kombëtar, and a Born-Died of 1905–1972? [/INST]\nQuery:\nWhich Term end has a Political Party of balli kombëtar, and a Born-Died of 1905–1972?\nOriginal Answer:\nSELECT term_end FROM table_name_23 WHERE political_party = \"balli kombëtar\" AND born_died = \"1905–1972\"\nGenerated Answer:\nSELECT term_end\nFROM table_name_23\nWHERE political_party = 'balli kombëtar'\nAND born_died = '1905–1972';\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_SQL()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T21:53:14.559370Z","iopub.execute_input":"2024-08-25T21:53:14.559773Z","iopub.status.idle":"2024-08-25T21:53:16.673542Z","shell.execute_reply.started":"2024-08-25T21:53:14.559737Z","shell.execute_reply":"2024-08-25T21:53:16.672617Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST] <<SYS>>\nYou are an text to SQL query translator. Users will ask you questions in English and you will generate a SQL query based on the provided SCHEMA.\nSCHEMA:\nCREATE TABLE table_name_22 (player VARCHAR, school_club_team VARCHAR)\n<</SYS>>\n\nWho is the Player for School/Club Team Illinois? [/INST]\nQuery:\nWho is the Player for School/Club Team Illinois?\nOriginal Answer:\nSELECT player FROM table_name_22 WHERE school_club_team = \"illinois\"\nGenerated Answer:\nSELECT player FROM table_name_22 WHERE school_club_team = 'Illinois';\n","output_type":"stream"}]}]}